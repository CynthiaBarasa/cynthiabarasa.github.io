{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/cynthycynthy/titanic-dataset-analysis?scriptVersionId=115364555\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"16f34cc2","metadata":{"papermill":{"duration":0.006761,"end_time":"2023-01-03T09:46:46.286206","exception":false,"start_time":"2023-01-03T09:46:46.279445","status":"completed"},"tags":[]},"source":[]},{"cell_type":"markdown","id":"753aef77","metadata":{"papermill":{"duration":0.004069,"end_time":"2023-01-03T09:46:46.294895","exception":false,"start_time":"2023-01-03T09:46:46.290826","status":"completed"},"tags":[]},"source":["# **1. Background of the Competition**\n","The Titanic dataset is a well-known dataset that provides information on the passengers who were onboard the fateful voyage of the RMS Titanic. The data includes details such as the passenger's name, age, gender, ticket class, fare paid, and information on their family members. The dataset also includes a column called \"Survived\" which indicates whether a passenger survived the disaster or not.\n","\n","There are a total of 891 rows in the dataset, with 12 columns. Some of the key columns in the dataset include:\n","\n","• PassengerId: a unique identifier for each passenger\n","• Survived: a binary variable that indicates whether the passenger survived (1) or did not survive (0) the disaster\n","• Pclass: the ticket class of the passenger (1 = first class, 2 = second class, 3 = third class)\n","• Name: the name of the passenger\n","• Sex: the gender of the passenger (male or female)\n","• Age: the age of the passenger (some values are missing)\n","• SibSp: the number of siblings or spouses the passenger had on board\n","• Parch: the number of parents or children the passenger had on board\n","• Ticket: the ticket number of the passenger\n","• Fare: the fare paid by the passenger\n","• Cabin: the cabin number of the passenger (some values are missing)\n","• Embarked: the port at which the passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)\n","\n","Overall, the key challenges I encountered when working on the Titanic dataset were: how to handle missing values and imbalanced classes, encode categorical variables, reduce the dimensionality of the dataset, and identify and handle noise in the data.\n","\n","Here are a few tips and resources that I found helpful when getting started in the Titanic dataset competition:\n","\n","Get familiar with the dataset\n","Pre-process the data\n","Split the data into training and test sets\n","Try out a few different algorithms\n","Tune the hyper parameters\n","Evaluate the model\n","Here are a few resources that I found helpful as I started Working on the competition:\n","• Kaggle's Titanic tutorial\n","• scikit-learn documentation.\n","• Pandas documentation"]},{"cell_type":"markdown","id":"ca46150f","metadata":{"papermill":{"duration":0.004074,"end_time":"2023-01-03T09:46:46.303323","exception":false,"start_time":"2023-01-03T09:46:46.299249","status":"completed"},"tags":[]},"source":[]},{"cell_type":"markdown","id":"e712bada","metadata":{"papermill":{"duration":0.004025,"end_time":"2023-01-03T09:46:46.311667","exception":false,"start_time":"2023-01-03T09:46:46.307642","status":"completed"},"tags":[]},"source":["# **2. Data Exploration**"]},{"cell_type":"code","execution_count":1,"id":"0fc26672","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-03T09:46:46.323449Z","iopub.status.busy":"2023-01-03T09:46:46.322296Z","iopub.status.idle":"2023-01-03T09:46:46.33526Z","shell.execute_reply":"2023-01-03T09:46:46.334474Z"},"papermill":{"duration":0.02187,"end_time":"2023-01-03T09:46:46.337738","exception":false,"start_time":"2023-01-03T09:46:46.315868","status":"completed"},"tags":[]},"outputs":[],"source":[" import pandas as pd   #data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","execution_count":2,"id":"cf97c5fc","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:46.349019Z","iopub.status.busy":"2023-01-03T09:46:46.347994Z","iopub.status.idle":"2023-01-03T09:46:46.356168Z","shell.execute_reply":"2023-01-03T09:46:46.355019Z"},"papermill":{"duration":0.016354,"end_time":"2023-01-03T09:46:46.35868","exception":false,"start_time":"2023-01-03T09:46:46.342326","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/titanic/train.csv\n","/kaggle/input/titanic/test.csv\n","/kaggle/input/titanic/gender_submission.csv\n"]}],"source":["#list all files under the input directory\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":3,"id":"5c55fb80","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:46.370054Z","iopub.status.busy":"2023-01-03T09:46:46.369223Z","iopub.status.idle":"2023-01-03T09:46:46.431892Z","shell.execute_reply":"2023-01-03T09:46:46.430219Z"},"papermill":{"duration":0.071773,"end_time":"2023-01-03T09:46:46.435044","exception":false,"start_time":"2023-01-03T09:46:46.363271","status":"completed"},"tags":[]},"outputs":[],"source":["data = pd.read_csv('/kaggle/input/titanic/train.csv') #Load data that was downloaded from Kaggle, train data\n","test = pd.read_csv('/kaggle/input/titanic/test.csv') #Load data that was downloaded from Kaggle, test data\n","test_ids = test[\"PassengerId\"]\n","\n","def clean(data): #Created a clean function to get some data\n","    data = data.drop([\"Ticket\", \"PassengerId\", \"Name\", \"Cabin\"], axis=1)\n","    \n","    #Dropped the Ticket, PassengerId, Name and Cabin because I think it doesn't give me a lot of information\n","    \n","    cols = [\"SibSp\", \"Parch\", \"Fare\", \"Age\"] #Columns that don't have a number in them\n","    for col in cols: #going through the columns\n","        data[col].fillna(data[col].median(), inplace=True) \n","        #Converting the columns to numbers, fill in the numbers that are not filled with their mean.\n","        \n","    data.Embarked.fillna(\"U\", inplace=True) #Fill the embarked with missing datapoints with unknown tokens\n","    return data\n","\n","data = clean(data)\n","test = clean(test)"]},{"cell_type":"code","execution_count":4,"id":"efe14ff4","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:46.449546Z","iopub.status.busy":"2023-01-03T09:46:46.448364Z","iopub.status.idle":"2023-01-03T09:46:46.473224Z","shell.execute_reply":"2023-01-03T09:46:46.472363Z"},"papermill":{"duration":0.034973,"end_time":"2023-01-03T09:46:46.475903","exception":false,"start_time":"2023-01-03T09:46:46.44093","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n","0         0       3    male  22.0      1      0   7.2500        S\n","1         1       1  female  38.0      1      0  71.2833        C\n","2         1       3  female  26.0      0      0   7.9250        S\n","3         1       1  female  35.0      1      0  53.1000        S\n","4         0       3    male  35.0      0      0   8.0500        S"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head(5) #Drop some columns and limit them to 5"]},{"cell_type":"code","execution_count":5,"id":"6897bb0c","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:46.487643Z","iopub.status.busy":"2023-01-03T09:46:46.486711Z","iopub.status.idle":"2023-01-03T09:46:47.650025Z","shell.execute_reply":"2023-01-03T09:46:47.64828Z"},"papermill":{"duration":1.171812,"end_time":"2023-01-03T09:46:47.652605","exception":false,"start_time":"2023-01-03T09:46:46.480793","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["['female' 'male']\n","['C' 'Q' 'S' 'U']\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n","0         0       3    1  22.0      1      0   7.2500         2\n","1         1       1    0  38.0      1      0  71.2833         0\n","2         1       3    0  26.0      0      0   7.9250         2\n","3         1       1    0  35.0      1      0  53.1000         2\n","4         0       3    1  35.0      0      0   8.0500         2"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn import preprocessing #using sklearn to convert strings to actual values\n","le = preprocessing.LabelEncoder() #Using the label encoder\n","columns = [\"Sex\", \"Embarked\"]\n","\n","for col in columns:\n","    data[col] = le.fit_transform(data[col]) #Doing the mapping of the data column\n","    test[col] = le.transform(test[col]) #Doing the mapping of the data column\n","    print(le.classes_) # print to see the conversion of the classes to integer e.g Femle is 1\n","      \n","data.head(5)"]},{"cell_type":"code","execution_count":6,"id":"c4f272b2","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:47.666115Z","iopub.status.busy":"2023-01-03T09:46:47.665639Z","iopub.status.idle":"2023-01-03T09:46:47.817696Z","shell.execute_reply":"2023-01-03T09:46:47.816225Z"},"papermill":{"duration":0.163093,"end_time":"2023-01-03T09:46:47.820805","exception":false,"start_time":"2023-01-03T09:46:47.657712","status":"completed"},"tags":[]},"outputs":[],"source":["#Using logistic regression to have a validation set to see how good it is\n","from sklearn.linear_model import LogisticRegression \n","from sklearn.model_selection import train_test_split\n","\n","y = data[\"Survived\"]\n","X = data.drop(\"Survived\", axis=1) #Dropping the column for the survived\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":7,"id":"4b412632","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:47.832726Z","iopub.status.busy":"2023-01-03T09:46:47.832279Z","iopub.status.idle":"2023-01-03T09:46:47.87705Z","shell.execute_reply":"2023-01-03T09:46:47.876022Z"},"papermill":{"duration":0.053632,"end_time":"2023-01-03T09:46:47.879577","exception":false,"start_time":"2023-01-03T09:46:47.825945","status":"completed"},"tags":[]},"outputs":[],"source":["clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train) #Logistic Regression to the classifier to specify the random state"]},{"cell_type":"code","execution_count":8,"id":"415bcc4b","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:47.892627Z","iopub.status.busy":"2023-01-03T09:46:47.891797Z","iopub.status.idle":"2023-01-03T09:46:47.903224Z","shell.execute_reply":"2023-01-03T09:46:47.902027Z"},"papermill":{"duration":0.020885,"end_time":"2023-01-03T09:46:47.905692","exception":false,"start_time":"2023-01-03T09:46:47.884807","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0.8100558659217877"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["predictions = clf.predict(X_val) #Know how good it is on the validation data that it hasn't seen\n","from sklearn.metrics import accuracy_score #Getting the accuracy\n","accuracy_score(y_val, predictions)"]},{"cell_type":"code","execution_count":9,"id":"50231151","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:47.918448Z","iopub.status.busy":"2023-01-03T09:46:47.917254Z","iopub.status.idle":"2023-01-03T09:46:47.925962Z","shell.execute_reply":"2023-01-03T09:46:47.924747Z"},"papermill":{"duration":0.017732,"end_time":"2023-01-03T09:46:47.928527","exception":false,"start_time":"2023-01-03T09:46:47.910795","status":"completed"},"tags":[]},"outputs":[],"source":["submission_preds = clf.predict(test) #Getting the submission Predictions"]},{"cell_type":"code","execution_count":10,"id":"1964c354","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:47.940474Z","iopub.status.busy":"2023-01-03T09:46:47.940034Z","iopub.status.idle":"2023-01-03T09:46:47.946494Z","shell.execute_reply":"2023-01-03T09:46:47.94536Z"},"papermill":{"duration":0.015268,"end_time":"2023-01-03T09:46:47.949088","exception":false,"start_time":"2023-01-03T09:46:47.93382","status":"completed"},"tags":[]},"outputs":[],"source":["#Generating a CSV file that can be submitted to Kaggle\n","df = pd.DataFrame({\"PassengerId\": test_ids.values,\n","                   \"Survived\": submission_preds,\n","                  })"]},{"cell_type":"code","execution_count":11,"id":"7762bcbd","metadata":{"execution":{"iopub.execute_input":"2023-01-03T09:46:47.962196Z","iopub.status.busy":"2023-01-03T09:46:47.960912Z","iopub.status.idle":"2023-01-03T09:46:47.970699Z","shell.execute_reply":"2023-01-03T09:46:47.969712Z"},"papermill":{"duration":0.018667,"end_time":"2023-01-03T09:46:47.973163","exception":false,"start_time":"2023-01-03T09:46:47.954496","status":"completed"},"tags":[]},"outputs":[],"source":["df.to_csv(\"final submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"id":"19e83d1f","metadata":{"papermill":{"duration":0.004745,"end_time":"2023-01-03T09:46:47.983166","exception":false,"start_time":"2023-01-03T09:46:47.978421","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":11.461521,"end_time":"2023-01-03T09:46:48.8134","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-01-03T09:46:37.351879","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}